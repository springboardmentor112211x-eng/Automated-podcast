# ğŸ§ Audio Analysis Project â€“ Automated Podcast Transcription & Topic Segmentation

## âœ… Problem Statement
Build an automated system that converts podcast/TED audio into structured, searchable, topic-wise knowledge using GenAI.

Core features implemented:
- Audio ingestion
- Transcription (Whisper)
- Topic segmentation
- GenAI-powered insights (topic labels + summaries)
- UI/dashboard + downloadable outputs

---

## ğŸš€ What I Built
An end-to-end pipeline that takes a long audio file and produces:
- Full transcript
- Topic-wise segmented transcript
- Topic labels (keywords)
- Topic summaries
- Downloadable JSON output
- Streamlit dashboard to view everything

---

## ğŸ—ï¸ Architecture / Pipeline
Audio File  
â†’ Audio Preprocessing (mono, 16kHz WAV)  
â†’ Chunking (30 seconds chunks + overlap)  
â†’ Speech-to-Text using Faster-Whisper  
â†’ Transcript Cleaning + Sentence Tokenization  
â†’ Sentence Embeddings (Sentence Transformers - MiniLM)  
â†’ Topic Segmentation (cosine similarity + min topic length)  
â†’ Topic Labeling (TF-IDF keywords)  
â†’ Topic Summarization (Transformers Summarizer)  
â†’ Streamlit Dashboard (View + Download)

---

## ğŸ§  Tech Stack
- Python
- Google Colab
- yt-dlp (dataset/audio download)
- pydub (audio preprocessing + chunking)
- Faster-Whisper (Speech-to-Text)
- NLTK (sentence tokenization)
- sentence-transformers (MiniLM embeddings)
- scikit-learn (cosine similarity + TF-IDF)
- transformers (summarization)
- Streamlit (UI/dashboard)

---

## ğŸ“Œ Topic Segmentation Logic
- Sentences are embedded using MiniLM
- Cosine similarity between consecutive sentences is computed
- A similarity drop below a threshold marks a topic boundary
- Minimum number of sentences per topic is enforced to avoid over-segmentation

âœ… Final Result: **15 meaningful topics generated**

---

## ğŸ“‚ Files Included
- `app.py` â†’ Streamlit dashboard
- `requirements.txt` â†’ Dependencies
- `Audio_Analysis.ipynb` â†’ Colab notebook (full pipeline)
- `final_topics_output.json` â†’ Topic-wise labeled summaries output
- `full_transcript.txt` â†’ Full transcript
- `cleaned_transcript.txt` â†’ Cleaned transcript
- `chunk_transcripts.json` â†’ Chunk-wise transcript output

---

## â–¶ï¸ How to Run (Local)
1) Install dependencies
```bash
pip install -r requirements.txt
2) Start Streamlit app
streamlit run app.py
